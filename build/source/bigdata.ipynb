{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b25ac82c-f34e-444b-8f05-5cb1fca7111b",
   "metadata": {
    "tags": [],
    "toc-hr-collapsed": true
   },
   "source": [
    "# 大数据之路\n",
    "## 数据技术\n",
    "## 数据模型\n",
    "    - 典型的数仓建设方法论\n",
    "        - ER模型\n",
    "        - 维度模型\n",
    "        - Data Vault模型\n",
    "        - Anchor模型\n",
    "    - 演变\n",
    "        - ODS+DSS -> ODL+BDL+IDL+ADL -> OneData\n",
    "### 名词术语\n",
    "- 数据域\n",
    "- 业务过程(事件)\n",
    "- 度量/原子指标: 如支付金额\n",
    "- 时间周期\n",
    "- 修饰类型: 如终端类型\n",
    "- 修饰词: 如手机支付、卡支付\n",
    "- 维度(实体对象): 如地域维度、时间维度\n",
    "- 维度属性: 如地域维度中的国家、省、市、区等\n",
    "- 派生指标: 原子指标+多个修饰词(可选)+时间周期, 如近一年的车票支付金额\n",
    "\n",
    "### 模型层次\n",
    "1. ODS\n",
    "1. CDM\n",
    "    - DWD\n",
    "    - DWS\n",
    "1. ADS\n",
    "\n",
    "## 数据管理\n",
    "## 数据应用"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3dd4bf6-16f3-4b97-85a9-eabf4135206d",
   "metadata": {},
   "source": [
    "# SparkSQL内核剖析\n",
    "## Spark背景\n",
    "## Spark基础知识\n",
    "- RDD\n",
    "- 窄依赖、宽依赖\n",
    "- Shuffle\n",
    "- 算子: transform、action\n",
    "- DAG、checkpoint\n",
    "- Driver程序"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b1ec737-955b-4503-9e47-ae65bbf6f2b8",
   "metadata": {},
   "source": [
    "## Spark SQL执行全过程概述"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a04b61f-6019-49d6-80e0-c26357c3d844",
   "metadata": {},
   "source": [
    "### 示例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1108f6f6-7adc-4c31-9370-1e4fd180fe7e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName(\"Python Spark SQL basic example\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "acec76fb-8819-4617-9462-c72ef3547751",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+----+\n",
      "|age| id|name|\n",
      "+---+---+----+\n",
      "| 29|  1|Kate|\n",
      "| 30|  2|Andy|\n",
      "| 10|  3|Tony|\n",
      "+---+---+----+\n",
      "\n",
      "+----+\n",
      "|name|\n",
      "+----+\n",
      "|Kate|\n",
      "|Andy|\n",
      "+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# df = spark.read.json(f\"{os.environ['SPARK_HOME']}/examples/src/main/resources/people.json\")\n",
    "df = spark.read.json('data/student.json')\n",
    "df.show()\n",
    "\n",
    "df.createOrReplaceTempView('student')\n",
    "\n",
    "spark.sql('select name from student where age > 18').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d26c7a52-669b-4791-83fd-a20020843e2e",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 逻辑计划 & 物理计划\n",
    "- LogicalPlan\n",
    "    - Unresolved LogicalPlan\n",
    "    - Analyzed LogicalPlan\n",
    "    - Optimized LogicalPlan\n",
    "- PhysicalPlan\n",
    "    - Iterator[PhyysicalPlan]\n",
    "    - SparkPlan\n",
    "    - Prepared SparkPlan\n",
    "- 从SQL语句的解析一直到提交之前,整个转换过程都在Spark集群的Driver端进行,不涉及分布式环境"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a22931e4-d35e-4cb7-ac41-0a0674411420",
   "metadata": {},
   "source": [
    "### 环境准备\n",
    "1. 收集sparkPlan的jar准备\n",
    "    - 创建demo-scala工程: 实现`org.apache.spark.sql.util.QueryExecutionListener`\n",
    "    - 收集sparkPlan写入`spark-plan-log/${funcName}_${uuid}.json`文件\n",
    "    - demo-scala package => demo-scala-1.0-SNAPSHOT.jar,放入samples/目录下(与spark-plan-log同级)\n",
    "1. 编写ss.cmd放入`samples/`\n",
    "    ```cmd\n",
    "    @echo on\n",
    "\n",
    "    rem\n",
    "    rem 指定queryExecutionListeners参数的spark-submit.cmd脚本\n",
    "    rem\n",
    "\n",
    "    cmd /V /E /C \"spark-submit.cmd  --conf spark.sql.queryExecutionListeners=org.example.framework.LineageListener --jars demo-scala-1.0-SNAPSHOT.jar %*\"\n",
    "    ```\n",
    "1. 创建`samples/sparksqlcore/`目录: 存放示例代码\n",
    "1. 创建`samples/spark-plan-log/`目录: 存放sparkPlan json数据\n",
    "1. 编写`samples/sparksqlcore/demo3_1.py`:\n",
    "    ```python\n",
    "    from pyspark.sql import SparkSession\n",
    "    import os\n",
    "\n",
    "    spark = SparkSession \\\n",
    "        .builder \\\n",
    "        .appName(\"Python Spark SQL basic example\") \\\n",
    "        .getOrCreate()\n",
    "\n",
    "    df = spark.read.json('data/student.json')\n",
    "    df.show()\n",
    "\n",
    "    df.createOrReplaceTempView('student')\n",
    "\n",
    "    spark.sql('select name from student where age > 18').show()\n",
    "    ```\n",
    "1. 切换目录至`samples/`下,执行`ss sparksqlcore/demo3_1.py`\n",
    "1. 查看`spark-plan-log/`收集的执行计划"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "884f68ad-002c-46dc-8108-d79eccb35c34",
   "metadata": {},
   "source": [
    "### 分析\n",
    "- `select name from student where age > 18`\n",
    "- sparkPlan\n",
    "    - 对应数据表: org.apache.spark.sql.execution.FileSourceScanExec\n",
    "    - 过滤逻辑:   org.apache.spark.sql.execution.FilterExec\n",
    "    - 列裁剪逻辑: org.apache.spark.sql.execution.ProjectExec\n",
    "    - 应该是自动添加的: org.apache.spark.sql.execution.CollectLimitExec"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdd47bc6-6a48-45de-a9b6-eeeb297fe7e8",
   "metadata": {},
   "source": [
    "### Catalyst\n",
    "- InternalRow\n",
    "- TreeNode\n",
    "- Expression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47fbeae0-584e-42a3-aea7-40282a1bb751",
   "metadata": {},
   "source": [
    "## Spark SQL编译器Parser\n",
    "- DSL(Domain Specific Language)\n",
    "- 非图灵完备的语言\n",
    "- ANTLR : another tool for language recognition\n",
    "    - ANTLR4\n",
    "    - sql/api/src/main/antlr4/org/apache/spark/sql/catalyst/parser/SqlBaseParser.g4(https://github.com/apache/spark/blob/master/sql/api/src/main/antlr4/org/apache/spark/sql/catalyst/parser/SqlBaseParser.g4)\n",
    "- 监听器模式\n",
    "- 访问者模式"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "toc-autonumbering": true
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
